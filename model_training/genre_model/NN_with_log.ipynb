{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f20e429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "initialized loader with 631 files and 638 chunks\n",
      "initialized loader with 96 files and 97 chunks\n",
      "initialized loader with 64 files and 65 chunks\n",
      "Data Loaded\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import batch_data_loader\n",
    "import numpy as np\n",
    "\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "\n",
    "CURRENT_MODEL = \"40_segments_more_epochs_180.pth\"\n",
    "\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "DETECTED_SEGMENTS = 50 #number of pitch/timbre segments being used\n",
    "TEST_SPLIT = 0.15 #percentage of data being used for testing (FROM TESTING FOLDER)\n",
    "VALIDATION_SPLIT = 0.1 #percentage of data being used for validation (FROM TESTING FOLDER)\n",
    "BATCH_SIZE = 1024\n",
    "\n",
    "train_loader, test_loader, validation_loader = batch_data_loader.load_MSD(DETECTED_SEGMENTS, TEST_SPLIT,\\\n",
    "                                                                                VALIDATION_SPLIT, BATCH_SIZE)\n",
    "\n",
    "numClasses = 15\n",
    "\n",
    "print(\"Data Loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89865dc5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TwoChannelCNN(\n",
      "  (layer1): Sequential(\n",
      "    (0): Conv2d(1, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Conv2d(1, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=30720, out_features=4096, bias=True)\n",
      "  (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "  (fc3): Linear(in_features=1024, out_features=15, bias=True)\n",
      ")\n",
      "Accuracy is: 99 %\n",
      "Epoch 121 took 382.104420 seconds \t Training Loss: 0.363886 \t Validation Loss: 0.085115 \t Final Accuracy: 0.997028\n",
      "Validation Loss Decreased(0.082811-->0.077007) \t Saving The Model\n",
      "Accuracy is: 99 %\n",
      "Epoch 122 took 378.438714 seconds \t Training Loss: 0.357279 \t Validation Loss: 0.077007 \t Final Accuracy: 0.997074\n",
      "Accuracy is: 99 %\n",
      "Epoch 123 took 378.507582 seconds \t Training Loss: 0.354395 \t Validation Loss: 0.077844 \t Final Accuracy: 0.997090\n",
      "Validation Loss Decreased(0.077007-->0.067889) \t Saving The Model\n",
      "Accuracy is: 99 %\n",
      "Epoch 124 took 377.078137 seconds \t Training Loss: 0.348786 \t Validation Loss: 0.067889 \t Final Accuracy: 0.997675\n",
      "Accuracy is: 99 %\n",
      "Epoch 125 took 376.436687 seconds \t Training Loss: 0.345370 \t Validation Loss: 0.074875 \t Final Accuracy: 0.997536\n",
      "Accuracy is: 99 %\n",
      "Epoch 126 took 376.743727 seconds \t Training Loss: 0.339695 \t Validation Loss: 0.070393 \t Final Accuracy: 0.998214\n",
      "Accuracy is: 99 %\n",
      "Epoch 127 took 376.662585 seconds \t Training Loss: 0.335349 \t Validation Loss: 0.070709 \t Final Accuracy: 0.997274\n",
      "Validation Loss Decreased(0.067889-->0.064611) \t Saving The Model\n",
      "Accuracy is: 99 %\n",
      "Epoch 128 took 378.999489 seconds \t Training Loss: 0.332097 \t Validation Loss: 0.064611 \t Final Accuracy: 0.997829\n",
      "Accuracy is: 99 %\n",
      "Epoch 129 took 377.754856 seconds \t Training Loss: 0.327753 \t Validation Loss: 0.065119 \t Final Accuracy: 0.997690\n",
      "Validation Loss Decreased(0.064611-->0.058336) \t Saving The Model\n",
      "Accuracy is: 99 %\n",
      "Epoch 130 took 375.516756 seconds \t Training Loss: 0.324723 \t Validation Loss: 0.058336 \t Final Accuracy: 0.998568\n",
      "Accuracy is: 99 %\n",
      "Epoch 131 took 378.947681 seconds \t Training Loss: 0.325196 \t Validation Loss: 0.060186 \t Final Accuracy: 0.998275\n",
      "Accuracy is: 99 %\n",
      "Epoch 132 took 377.580409 seconds \t Training Loss: 0.317908 \t Validation Loss: 0.059426 \t Final Accuracy: 0.998568\n",
      "Validation Loss Decreased(0.058336-->0.053220) \t Saving The Model\n",
      "Accuracy is: 99 %\n",
      "Epoch 133 took 376.182655 seconds \t Training Loss: 0.315611 \t Validation Loss: 0.053220 \t Final Accuracy: 0.998660\n",
      "Validation Loss Decreased(0.053220-->0.052063) \t Saving The Model\n",
      "Accuracy is: 99 %\n",
      "Epoch 134 took 378.324979 seconds \t Training Loss: 0.312075 \t Validation Loss: 0.052063 \t Final Accuracy: 0.998491\n",
      "Validation Loss Decreased(0.052063-->0.050243) \t Saving The Model\n",
      "Accuracy is: 99 %\n",
      "Epoch 135 took 378.857339 seconds \t Training Loss: 0.309851 \t Validation Loss: 0.050243 \t Final Accuracy: 0.998629\n",
      "Accuracy is: 99 %\n",
      "Epoch 136 took 375.032091 seconds \t Training Loss: 0.305077 \t Validation Loss: 0.052550 \t Final Accuracy: 0.998629\n",
      "Accuracy is: 99 %\n",
      "Epoch 137 took 370.429538 seconds \t Training Loss: 0.300780 \t Validation Loss: 0.055427 \t Final Accuracy: 0.998891\n",
      "Accuracy is: 99 %\n",
      "Epoch 138 took 357.502920 seconds \t Training Loss: 0.297127 \t Validation Loss: 0.051177 \t Final Accuracy: 0.999107\n",
      "Validation Loss Decreased(0.050243-->0.049633) \t Saving The Model\n",
      "Accuracy is: 99 %\n",
      "Epoch 139 took 357.599835 seconds \t Training Loss: 0.296076 \t Validation Loss: 0.049633 \t Final Accuracy: 0.998845\n",
      "Validation Loss Decreased(0.049633-->0.042999) \t Saving The Model\n",
      "Accuracy is: 99 %\n",
      "Epoch 140 took 360.805352 seconds \t Training Loss: 0.293270 \t Validation Loss: 0.042999 \t Final Accuracy: 0.999122\n",
      "Accuracy is: 99 %\n",
      "Epoch 141 took 356.733291 seconds \t Training Loss: 0.291861 \t Validation Loss: 0.045034 \t Final Accuracy: 0.999292\n",
      "Accuracy is: 99 %\n",
      "Epoch 142 took 356.441591 seconds \t Training Loss: 0.286053 \t Validation Loss: 0.046285 \t Final Accuracy: 0.998891\n",
      "Accuracy is: 99 %\n",
      "Epoch 143 took 352.066542 seconds \t Training Loss: 0.280736 \t Validation Loss: 0.043579 \t Final Accuracy: 0.999184\n",
      "Validation Loss Decreased(0.042999-->0.040577) \t Saving The Model\n",
      "Accuracy is: 99 %\n",
      "Epoch 144 took 360.259535 seconds \t Training Loss: 0.281214 \t Validation Loss: 0.040577 \t Final Accuracy: 0.999292\n",
      "Validation Loss Decreased(0.040577-->0.040295) \t Saving The Model\n",
      "Accuracy is: 99 %\n",
      "Epoch 145 took 352.720062 seconds \t Training Loss: 0.278240 \t Validation Loss: 0.040295 \t Final Accuracy: 0.999076\n",
      "Validation Loss Decreased(0.040295-->0.039316) \t Saving The Model\n",
      "Accuracy is: 99 %\n",
      "Epoch 146 took 360.529948 seconds \t Training Loss: 0.275262 \t Validation Loss: 0.039316 \t Final Accuracy: 0.999261\n",
      "Validation Loss Decreased(0.039316-->0.036733) \t Saving The Model\n",
      "Accuracy is: 99 %\n",
      "Epoch 147 took 358.824720 seconds \t Training Loss: 0.272957 \t Validation Loss: 0.036733 \t Final Accuracy: 0.999168\n",
      "Validation Loss Decreased(0.036733-->0.034558) \t Saving The Model\n",
      "Accuracy is: 99 %\n",
      "Epoch 148 took 353.081630 seconds \t Training Loss: 0.272569 \t Validation Loss: 0.034558 \t Final Accuracy: 0.999476\n",
      "Validation Loss Decreased(0.034558-->0.034006) \t Saving The Model\n",
      "Accuracy is: 99 %\n",
      "Epoch 149 took 360.546995 seconds \t Training Loss: 0.266847 \t Validation Loss: 0.034006 \t Final Accuracy: 0.999523\n",
      "Accuracy is: 99 %\n",
      "Epoch 150 took 358.695152 seconds \t Training Loss: 0.264537 \t Validation Loss: 0.039099 \t Final Accuracy: 0.999091\n",
      "Validation Loss Decreased(0.034006-->0.033893) \t Saving The Model\n",
      "Accuracy is: 99 %\n",
      "Epoch 151 took 361.032981 seconds \t Training Loss: 0.259325 \t Validation Loss: 0.033893 \t Final Accuracy: 0.999476\n",
      "Validation Loss Decreased(0.033893-->0.032348) \t Saving The Model\n",
      "Accuracy is: 99 %\n",
      "Epoch 152 took 363.379021 seconds \t Training Loss: 0.260074 \t Validation Loss: 0.032348 \t Final Accuracy: 0.999600\n",
      "Validation Loss Decreased(0.032348-->0.031405) \t Saving The Model\n",
      "Accuracy is: 99 %\n",
      "Epoch 153 took 364.081448 seconds \t Training Loss: 0.257902 \t Validation Loss: 0.031405 \t Final Accuracy: 0.999600\n",
      "Validation Loss Decreased(0.031405-->0.029533) \t Saving The Model\n",
      "Accuracy is: 99 %\n",
      "Epoch 154 took 369.383908 seconds \t Training Loss: 0.254961 \t Validation Loss: 0.029533 \t Final Accuracy: 0.999569\n",
      "Accuracy is: 99 %\n",
      "Epoch 155 took 367.576424 seconds \t Training Loss: 0.254321 \t Validation Loss: 0.033885 \t Final Accuracy: 0.999415\n",
      "Validation Loss Decreased(0.029533-->0.029517) \t Saving The Model\n",
      "Accuracy is: 99 %\n",
      "Epoch 156 took 364.502322 seconds \t Training Loss: 0.249767 \t Validation Loss: 0.029517 \t Final Accuracy: 0.999600\n",
      "Accuracy is: 99 %\n",
      "Epoch 157 took 362.320864 seconds \t Training Loss: 0.246328 \t Validation Loss: 0.031736 \t Final Accuracy: 0.999553\n",
      "Validation Loss Decreased(0.029517-->0.027323) \t Saving The Model\n",
      "Accuracy is: 99 %\n",
      "Epoch 158 took 363.166430 seconds \t Training Loss: 0.246185 \t Validation Loss: 0.027323 \t Final Accuracy: 0.999507\n",
      "Accuracy is: 99 %\n",
      "Epoch 159 took 361.429585 seconds \t Training Loss: 0.245010 \t Validation Loss: 0.031371 \t Final Accuracy: 0.999430\n",
      "Accuracy is: 99 %\n",
      "Epoch 160 took 362.655929 seconds \t Training Loss: 0.242080 \t Validation Loss: 0.028190 \t Final Accuracy: 0.999507\n",
      "Accuracy is: 99 %\n",
      "Epoch 161 took 369.540192 seconds \t Training Loss: 0.239148 \t Validation Loss: 0.028009 \t Final Accuracy: 0.999754\n",
      "Validation Loss Decreased(0.027323-->0.027272) \t Saving The Model\n",
      "Accuracy is: 99 %\n",
      "Epoch 162 took 357.093989 seconds \t Training Loss: 0.237884 \t Validation Loss: 0.027272 \t Final Accuracy: 0.999661\n",
      "Validation Loss Decreased(0.027272-->0.022756) \t Saving The Model\n",
      "Accuracy is: 99 %\n",
      "Epoch 163 took 362.486788 seconds \t Training Loss: 0.235167 \t Validation Loss: 0.022756 \t Final Accuracy: 0.999677\n",
      "Accuracy is: 99 %\n",
      "Epoch 164 took 364.168677 seconds \t Training Loss: 0.234889 \t Validation Loss: 0.025063 \t Final Accuracy: 0.999661\n",
      "Accuracy is: 99 %\n",
      "Epoch 165 took 356.994912 seconds \t Training Loss: 0.233283 \t Validation Loss: 0.026035 \t Final Accuracy: 0.999584\n",
      "Accuracy is: 99 %\n",
      "Epoch 166 took 372.155141 seconds \t Training Loss: 0.230468 \t Validation Loss: 0.023649 \t Final Accuracy: 0.999415\n",
      "Accuracy is: 99 %\n",
      "Epoch 167 took 370.787641 seconds \t Training Loss: 0.227765 \t Validation Loss: 0.024467 \t Final Accuracy: 0.999769\n",
      "Validation Loss Decreased(0.022756-->0.021270) \t Saving The Model\n",
      "Accuracy is: 99 %\n",
      "Epoch 168 took 375.584841 seconds \t Training Loss: 0.225580 \t Validation Loss: 0.021270 \t Final Accuracy: 0.999908\n",
      "Accuracy is: 99 %\n",
      "Epoch 169 took 382.030756 seconds \t Training Loss: 0.226677 \t Validation Loss: 0.023515 \t Final Accuracy: 0.999677\n",
      "Accuracy is: 99 %\n",
      "Epoch 170 took 377.216946 seconds \t Training Loss: 0.225632 \t Validation Loss: 0.021656 \t Final Accuracy: 0.999615\n",
      "Accuracy is: 99 %\n",
      "Epoch 171 took 374.043382 seconds \t Training Loss: 0.222174 \t Validation Loss: 0.023621 \t Final Accuracy: 0.999692\n",
      "Validation Loss Decreased(0.021270-->0.020785) \t Saving The Model\n",
      "Accuracy is: 99 %\n",
      "Epoch 172 took 369.229807 seconds \t Training Loss: 0.220370 \t Validation Loss: 0.020785 \t Final Accuracy: 0.999861\n",
      "Validation Loss Decreased(0.020785-->0.020557) \t Saving The Model\n",
      "Accuracy is: 99 %\n",
      "Epoch 173 took 378.516444 seconds \t Training Loss: 0.218004 \t Validation Loss: 0.020557 \t Final Accuracy: 0.999784\n",
      "Validation Loss Decreased(0.020557-->0.019681) \t Saving The Model\n",
      "Accuracy is: 99 %\n",
      "Epoch 174 took 380.446509 seconds \t Training Loss: 0.213910 \t Validation Loss: 0.019681 \t Final Accuracy: 0.999831\n",
      "Accuracy is: 99 %\n",
      "Epoch 175 took 364.317539 seconds \t Training Loss: 0.213080 \t Validation Loss: 0.022898 \t Final Accuracy: 0.999831\n",
      "Accuracy is: 99 %\n",
      "Epoch 176 took 364.460042 seconds \t Training Loss: 0.212312 \t Validation Loss: 0.020985 \t Final Accuracy: 0.999769\n",
      "Validation Loss Decreased(0.019681-->0.018849) \t Saving The Model\n",
      "Accuracy is: 99 %\n",
      "Epoch 177 took 367.327676 seconds \t Training Loss: 0.213109 \t Validation Loss: 0.018849 \t Final Accuracy: 0.999831\n",
      "Validation Loss Decreased(0.018849-->0.017377) \t Saving The Model\n",
      "Accuracy is: 99 %\n",
      "Epoch 178 took 367.276348 seconds \t Training Loss: 0.209536 \t Validation Loss: 0.017377 \t Final Accuracy: 0.999861\n",
      "Validation Loss Decreased(0.017377-->0.016984) \t Saving The Model\n",
      "Accuracy is: 99 %\n",
      "Epoch 179 took 366.068658 seconds \t Training Loss: 0.207057 \t Validation Loss: 0.016984 \t Final Accuracy: 0.999800\n",
      "Accuracy is: 99 %\n",
      "Epoch 180 took 374.800033 seconds \t Training Loss: 0.207295 \t Validation Loss: 0.019888 \t Final Accuracy: 0.999892\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "class TwoChannelCNN(nn.Module):\n",
    "    def __init__(self, numClasses):\n",
    "        super(TwoChannelCNN, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(1, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(30720, 4096)\n",
    "        self.fc2 = nn.Linear(4096, 1024)\n",
    "        self.fc3 = nn.Linear(1024, numClasses)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x has shape (batch_size, 2, 50, 12)\n",
    "        x1 = x[:, 0, :40, :].unsqueeze(1)  # shape: (batch_size, 1, 40, 12)\n",
    "        x2 = x[:, 1, :40, :].unsqueeze(1)  # shape: (batch_size, 1, 40, 12)\n",
    "\n",
    "        out1 = self.layer1(x1)  # shape: (batch_size, 64, 6, 3)\n",
    "        out2 = self.layer2(x2)  # shape: (batch_size, 64, 6, 3)\n",
    "\n",
    "        out1 = self.dropout(out1)\n",
    "        out2 = self.dropout(out2)\n",
    "\n",
    "        out = torch.cat((out1, out2), dim=1)  # shape: (batch_size, 128, 6, 3)\n",
    "        out = out.view(out.size(0), -1)  # shape: (batch_size, 128*6*3)\n",
    "#         print(f'shape: {out.shape}')\n",
    "        out = F.relu(self.fc1(out))\n",
    "        out = self.dropout(out)\n",
    "        out = F.relu(self.fc2(out))\n",
    "        out = self.fc3(out)\n",
    "        return out\n",
    "    \n",
    "model = TwoChannelCNN(numClasses).to(device)\n",
    "\n",
    "#if you want to load a previously saved model, use this\n",
    "#so training on one model can happen in multiple sessions\n",
    "# saved_model = torch.load('30_segments_more_epochs_180.pth')\n",
    "# model.load_state_dict(saved_model)\n",
    "\n",
    "\n",
    "print(model)\n",
    "\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "epochs = 120\n",
    "min_valid_loss = 0.082811\n",
    " \n",
    "#start train loop\n",
    "for e in range(epochs, 180):\n",
    "    start = time.time()\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    for i, (data,labels) in enumerate(train_loader):\n",
    "        data, labels = data.to(device), labels.to(device)\n",
    "         \n",
    "        # Clear the gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Forward Pass\n",
    "        target = model(data.float())\n",
    "        # Find the Loss\n",
    "        loss = criterion(target,labels)\n",
    "        # Calculate gradients\n",
    "        loss.backward()\n",
    "        # Update Weights\n",
    "        optimizer.step()\n",
    "        # Calculate Loss\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "    train_loss = train_loss / len(train_loader)\n",
    "    \n",
    "    valid_loss = 0.0\n",
    "    model.eval()     # Optional when not using Model Specific layer\n",
    "    for data, labels in validation_loader:\n",
    "        # Transfer Data to GPU if available\n",
    "        data, labels = data.to(device), labels.to(device)\n",
    "         \n",
    "        # Forward Pass\n",
    "        target = model(data.float())\n",
    "        # Find the Loss\n",
    "        loss = criterion(target,labels)\n",
    "        # Calculate Loss\n",
    "        valid_loss += loss.item()\n",
    "        \n",
    "    valid_loss = valid_loss / len(validation_loader)\n",
    "    \n",
    "  \n",
    "    if min_valid_loss > valid_loss:\n",
    "        print(f'Validation Loss Decreased({min_valid_loss:.6f}-->{valid_loss:.6f}) \\t Saving The Model')\n",
    "        min_valid_loss = valid_loss\n",
    "         \n",
    "        # Saving State Dict\n",
    "        torch.save(model.state_dict(), '40_segments_more_epochs_180.pth')\n",
    "    running_accuracy = 0 \n",
    "    total = 0 \n",
    "\n",
    "    # saved_model = torch.load(CURRENT_MODEL)\n",
    "\n",
    "    # model = TwoChannelCNN(numClasses).to(device)\n",
    "    # model.load_state_dict(saved_model)\n",
    "\n",
    "\n",
    "\n",
    "    with torch.no_grad(): \n",
    "        for i, data in enumerate(test_loader,0): \n",
    "            inputs, labels = data\n",
    "\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            predictions = model(inputs.float()) \n",
    "            predictions = torch.argmax(predictions, dim=1)\n",
    "            total += len(labels)\n",
    "            running_accuracy += (predictions == labels).sum().item() \n",
    "\n",
    "        print('Accuracy is: %d %%' % (100 * running_accuracy / total))    \n",
    "\n",
    "    final_accuracy = running_accuracy / total \n",
    "    \n",
    "    end = time.time()\n",
    "    print(f'Epoch {e+1} took {(end-start):.6f} seconds \\t Training Loss: {train_loss:.6f} \\t Validation Loss: {valid_loss:.6f} \\t Final Accuracy: {final_accuracy:.6f}')\n",
    "    \n",
    "# order of epochs, training_loss, validation_loss, fina\n",
    "    with open('NN_log.txt', 'a') as f:\n",
    "        # write the epochs\n",
    "        f.write(str(e))\n",
    "        f.write(',')        \n",
    "        f.write(str(train_loss))\n",
    "        f.write(',')\n",
    "        f.write(str(valid_loss))\n",
    "        f.write(',')\n",
    "        f.write(str(final_accuracy))\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3585efae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is: 97 %\n",
      "0.9777167269344418\n"
     ]
    }
   ],
   "source": [
    "running_accuracy = 0 \n",
    "total = 0 \n",
    "\n",
    "# saved_model = torch.load(CURRENT_MODEL)\n",
    "\n",
    "# model = TwoChannelCNN(numClasses).to(device)\n",
    "# model.load_state_dict(saved_model)\n",
    "\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad(): \n",
    "    for i, data in enumerate(test_loader,0): \n",
    "        inputs, labels = data\n",
    "        \n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        predictions = model(inputs.float()) \n",
    "        predictions = torch.argmax(predictions, dim=1)\n",
    "        total += len(labels)\n",
    "        running_accuracy += (predictions == labels).sum().item() \n",
    "\n",
    "    print('Accuracy is: %d %%' % (100 * running_accuracy / total))    \n",
    "\n",
    "final_accuracy = running_accuracy / total \n",
    "print(final_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcaa1a3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
