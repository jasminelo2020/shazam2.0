{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import load_csv_pitch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Data Loaded\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "   \"cuda\" if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(device)\n",
    "# device = \"cpu\"\n",
    "\n",
    "BATCH_SIZE = 3500\n",
    "train_loader, test_loader, validation_loader = load_csv_pitch.load_MSD(batch_size=BATCH_SIZE, device=device)\n",
    "\n",
    "print(\"Data Loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model(\n",
      "  (conv): Conv1d(1, 6, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "  (maxpool): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=13212, out_features=5000, bias=True)\n",
      "  (fc2): Linear(in_features=5000, out_features=1000, bias=True)\n",
      "  (fc3): Linear(in_features=1000, out_features=12, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "class model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(model, self).__init__()\n",
    "        self.conv = nn.Conv1d(1, 6, 9, 1, 4)\n",
    "        self.maxpool = nn.MaxPool1d(3, 3)\n",
    "\n",
    "        self.fc1 = nn.Linear(13212, 5000)\n",
    "        self.fc2 = nn.Linear(5000, 1000)\n",
    "        self.fc3 = nn.Linear(1000, 12)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.conv(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        max_values, _ = torch.max(x, dim = 1, keepdim = True)\n",
    "        x = x / max_values\n",
    "        return x\n",
    "        \n",
    "model = model().to(device)\n",
    "# saved_model = torch.load('models/timbre_model_epoch_10.pth')\n",
    "# model.load_state_dict(saved_model)\n",
    "\n",
    "print(model)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "epochs = 20\n",
    "min_valid_loss = 0.1160474456846714"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "205it [44:04, 12.90s/it]\n",
      "42it [03:15,  4.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8/20\n",
      "Start @ 14:5, End @ 14:52\n",
      "Epoch Duration: 2840.78s\n",
      "Training Loss: 0.125356\n",
      "Validation Loss: 0.123532\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "205it [46:39, 13.65s/it]\n",
      "42it [02:57,  4.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss decreased: 0.1160474456846714 -> 0.10756584789071764\n",
      "saving current model\n",
      "Epoch: 9/20\n",
      "Start @ 14:52, End @ 15:42\n",
      "Epoch Duration: 2977.66s\n",
      "Training Loss: 0.108540\n",
      "Validation Loss: 0.107566\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "205it [42:15, 12.37s/it]\n",
      "42it [03:01,  4.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss decreased: 0.10756584789071764 -> 0.08665809647313186\n",
      "saving current model\n",
      "Epoch: 10/20\n",
      "Start @ 15:42, End @ 16:27\n",
      "Epoch Duration: 2717.18s\n",
      "Training Loss: 0.092026\n",
      "Validation Loss: 0.086658\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "205it [42:53, 12.55s/it]\n",
      "42it [03:14,  4.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss decreased: 0.08665809647313186 -> 0.08346643777830261\n",
      "saving current model\n",
      "Epoch: 11/20\n",
      "Start @ 16:27, End @ 17:13\n",
      "Epoch Duration: 2768.66s\n",
      "Training Loss: 0.072164\n",
      "Validation Loss: 0.083466\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "205it [45:10, 13.22s/it]\n",
      "42it [02:59,  4.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss decreased: 0.08346643777830261 -> 0.08100792898663453\n",
      "saving current model\n",
      "Epoch: 12/20\n",
      "Start @ 17:13, End @ 18:1\n",
      "Epoch Duration: 2891.21s\n",
      "Training Loss: 0.063000\n",
      "Validation Loss: 0.081008\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "205it [43:27, 12.72s/it]\n",
      "42it [02:59,  4.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss decreased: 0.08100792898663453 -> 0.06797928416303226\n",
      "saving current model\n",
      "Epoch: 13/20\n",
      "Start @ 18:1, End @ 18:48\n",
      "Epoch Duration: 2786.87s\n",
      "Training Loss: 0.054534\n",
      "Validation Loss: 0.067979\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "205it [43:41, 12.79s/it]\n",
      "42it [03:05,  4.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss decreased: 0.06797928416303226 -> 0.06760534014375437\n",
      "saving current model\n",
      "Epoch: 14/20\n",
      "Start @ 18:48, End @ 19:35\n",
      "Epoch Duration: 2807.36s\n",
      "Training Loss: 0.052985\n",
      "Validation Loss: 0.067605\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "205it [45:22, 13.28s/it]\n",
      "0it [00:28, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"c:\\Users\\So\\anaconda3\\envs\\shazam\\lib\\site-packages\\torch\\utils\\data\\_utils\\worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"c:\\Users\\So\\anaconda3\\envs\\shazam\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 53, in fetch\n    data = self.dataset[possibly_batched_index]\n  File \"c:\\Users\\So\\Documents\\code\\shazam\\load_csv_pitch.py\", line 50, in __getitem__\n    return  torch.tensor(y).to(self.device), torch.tensor(pitch).to(self.device)\nRuntimeError: CUDA error: CUDA-capable device(s) is/are busy or unavailable\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 29\u001b[0m\n\u001b[0;32m     26\u001b[0m train_loss \u001b[39m=\u001b[39m train_loss \u001b[39m/\u001b[39m (i \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[0;32m     28\u001b[0m \u001b[39m# testing valiation loss\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m \u001b[39mfor\u001b[39;00m i, (data,labels) \u001b[39min\u001b[39;00m tqdm(\u001b[39menumerate\u001b[39m(validation_loader)):\n\u001b[0;32m     30\u001b[0m     data, labels \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mto(device), labels\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m     32\u001b[0m     \u001b[39m# Forward Pass\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\So\\anaconda3\\envs\\shazam\\lib\\site-packages\\tqdm\\std.py:1178\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1175\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[0;32m   1177\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1178\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[0;32m   1179\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[0;32m   1180\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1181\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\So\\anaconda3\\envs\\shazam\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    631\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    632\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 633\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    634\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    635\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    636\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\So\\anaconda3\\envs\\shazam\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1345\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1343\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1344\u001b[0m     \u001b[39mdel\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_task_info[idx]\n\u001b[1;32m-> 1345\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_process_data(data)\n",
      "File \u001b[1;32mc:\\Users\\So\\anaconda3\\envs\\shazam\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1371\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m   1369\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_try_put_index()\n\u001b[0;32m   1370\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[1;32m-> 1371\u001b[0m     data\u001b[39m.\u001b[39;49mreraise()\n\u001b[0;32m   1372\u001b[0m \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[1;32mc:\\Users\\So\\anaconda3\\envs\\shazam\\lib\\site-packages\\torch\\_utils.py:644\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    640\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m    641\u001b[0m     \u001b[39m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[0;32m    642\u001b[0m     \u001b[39m# instantiate since we don't know how to\u001b[39;00m\n\u001b[0;32m    643\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(msg) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 644\u001b[0m \u001b[39mraise\u001b[39;00m exception\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"c:\\Users\\So\\anaconda3\\envs\\shazam\\lib\\site-packages\\torch\\utils\\data\\_utils\\worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"c:\\Users\\So\\anaconda3\\envs\\shazam\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 53, in fetch\n    data = self.dataset[possibly_batched_index]\n  File \"c:\\Users\\So\\Documents\\code\\shazam\\load_csv_pitch.py\", line 50, in __getitem__\n    return  torch.tensor(y).to(self.device), torch.tensor(pitch).to(self.device)\nRuntimeError: CUDA error: CUDA-capable device(s) is/are busy or unavailable\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n\n"
     ]
    }
   ],
   "source": [
    "#start train loop\n",
    "for e in range(7, epochs):\n",
    "    start = time.time()\n",
    "    start_time = datetime.datetime.now()\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    validation_loss = 0.0\n",
    "    \n",
    "    # actual model training\n",
    "    for i, (data,labels) in tqdm(enumerate(train_loader)):\n",
    "        data, labels = data.to(device), labels.to(device)\n",
    "         \n",
    "        # Clear the gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Forward Pass\n",
    "        target = model(data.float())\n",
    "        # Find the Loss\n",
    "        loss = criterion(target,labels.float())\n",
    "        # Calculate gradients\n",
    "        loss.backward()\n",
    "        # Update Weights\n",
    "        optimizer.step()\n",
    "        # Calculate Loss\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    train_loss = train_loss / (i + 1)\n",
    "\n",
    "    # testing valiation loss\n",
    "    for i, (data,labels) in tqdm(enumerate(validation_loader)):\n",
    "        data, labels = data.to(device), labels.to(device)\n",
    "         \n",
    "        # Forward Pass\n",
    "        target = model(data.float())\n",
    "        # Find the validation loss\n",
    "        loss = criterion(target,labels.float())\n",
    "\n",
    "        # Calculate Loss\n",
    "        validation_loss += loss.item()\n",
    "\n",
    "    validation_loss = validation_loss / (i + 1)\n",
    "    \n",
    "    if validation_loss < min_valid_loss:\n",
    "        print(f'validation loss decreased: {min_valid_loss} -> {validation_loss}')\n",
    "        print(f'saving current model')\n",
    "        torch.save(model.state_dict(), f'pitch_model_epoch_{e + 1}.pth')\n",
    "        min_valid_loss = validation_loss\n",
    "\n",
    "\n",
    "    end = time.time()\n",
    "    end_time = datetime.datetime.now()\n",
    "    print(f\"Epoch: {e+1}/{epochs}\")\n",
    "    print(f'Start @ {start_time.hour}:{start_time.minute}, End @ {end_time.hour}:{end_time.minute}')\n",
    "    print(f\"Epoch Duration: {end-start:.2f}s\")\n",
    "    print(f\"Training Loss: {train_loss:.6f}\")\n",
    "    print(f\"Validation Loss: {validation_loss:.6f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shazam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
